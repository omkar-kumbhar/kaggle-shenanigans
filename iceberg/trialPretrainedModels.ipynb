{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'cats_and_dogs_small'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8192)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 2s 977us/step - loss: 0.5635 - acc: 0.7035 - val_loss: 0.4235 - val_acc: 0.8350\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 0.4139 - acc: 0.8130 - val_loss: 0.3494 - val_acc: 0.8730\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 1s 545us/step - loss: 0.3386 - acc: 0.8545 - val_loss: 0.3142 - val_acc: 0.8840\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 1s 547us/step - loss: 0.3028 - acc: 0.8765 - val_loss: 0.2928 - val_acc: 0.8870\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 0.2683 - acc: 0.8945 - val_loss: 0.2792 - val_acc: 0.8930\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 0.2551 - acc: 0.9020 - val_loss: 0.2694 - val_acc: 0.8930\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 1s 549us/step - loss: 0.2349 - acc: 0.9085 - val_loss: 0.2607 - val_acc: 0.8990\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 1s 623us/step - loss: 0.2184 - acc: 0.9190 - val_loss: 0.2709 - val_acc: 0.8850\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 1s 501us/step - loss: 0.2189 - acc: 0.9220 - val_loss: 0.2669 - val_acc: 0.8860\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.2046 - acc: 0.9250 - val_loss: 0.2478 - val_acc: 0.9020\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 0.1952 - acc: 0.9275 - val_loss: 0.2458 - val_acc: 0.9030\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 0.1854 - acc: 0.9350 - val_loss: 0.2435 - val_acc: 0.9010\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 0.1767 - acc: 0.9380 - val_loss: 0.2435 - val_acc: 0.8990\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 1s 622us/step - loss: 0.1607 - acc: 0.9435 - val_loss: 0.2439 - val_acc: 0.8980\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 1s 634us/step - loss: 0.1621 - acc: 0.9405 - val_loss: 0.2394 - val_acc: 0.9040\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 0.1559 - acc: 0.9460 - val_loss: 0.2382 - val_acc: 0.9040\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 0.1447 - acc: 0.9555 - val_loss: 0.2379 - val_acc: 0.9040\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 0.1393 - acc: 0.9530 - val_loss: 0.2357 - val_acc: 0.9020\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 0.1415 - acc: 0.9530 - val_loss: 0.2416 - val_acc: 0.9050\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 1s 546us/step - loss: 0.1327 - acc: 0.9545 - val_loss: 0.2357 - val_acc: 0.9030\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 0.1235 - acc: 0.9600 - val_loss: 0.2378 - val_acc: 0.9020\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 0.1140 - acc: 0.9665 - val_loss: 0.2384 - val_acc: 0.9050\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 1s 550us/step - loss: 0.1161 - acc: 0.9625 - val_loss: 0.2330 - val_acc: 0.9010\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 0.1096 - acc: 0.9680 - val_loss: 0.2430 - val_acc: 0.9010\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 0.1061 - acc: 0.9650 - val_loss: 0.2365 - val_acc: 0.9060\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 0.1003 - acc: 0.9700 - val_loss: 0.2526 - val_acc: 0.8940\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 0.1053 - acc: 0.9640 - val_loss: 0.2364 - val_acc: 0.9030\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 0.0960 - acc: 0.9715 - val_loss: 0.2371 - val_acc: 0.9030\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 0.0922 - acc: 0.9745 - val_loss: 0.2445 - val_acc: 0.9030\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 0.0905 - acc: 0.9755 - val_loss: 0.2379 - val_acc: 0.9040\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0xKnVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x213acec0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x213afd69470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      " - 25s - loss: 0.6092 - acc: 0.6685 - val_loss: 0.4844 - val_acc: 0.7700\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-381012aec1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m       verbose=2)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\My Legion\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
