{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8fc6c3e84f282d0e6f664caf9848297b6c62a16"
   },
   "source": [
    "### U-net with simple Resnet Blocks v2, can get 0.80+\n",
    "* Original version : \n",
    "  https://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks\n",
    "        \n",
    "        \n",
    "#### update log\n",
    "1.   Cancel last dropout (seems better)\n",
    "2.  modify convolution_block, to be more consistant with the standard resent model. \n",
    "      * https://arxiv.org/abs/1603.05027\n",
    "3. Use faster  IOU metric score code,\n",
    "      * https://www.kaggle.com/donchuk/fast-implementation-of-scoring-metric\n",
    "4. Use  binary_crossentropy loss and then Lovász-hinge loss (very slow!)\n",
    "     * Lovász-hinge loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "     \n",
    "Limit the max epochs number to make the kernel finish in the limit of 6 hours, better score can be achived at more epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "2c36d16775556c3e358edefab5710dc1541ccfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilated_conv.model\n",
      "dilated_conv.csv\n"
     ]
    }
   ],
   "source": [
    "version = 5\n",
    "basic_name = 'dilated_conv'\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "63c469280793719bf311d51e6ba2cdaea157d175"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "1a64babef03b9a0dbc94387a1dad54971c3e028d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "80c3768717007fb5f087d3e01619f1a9f9a3beac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de8bb0c0ea6452986cf13fb61475838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "9f55103f7daad6f03ec874c643077fe686c31bee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6958e1097b41e6b29f2da33ee7d45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "010066dd50ef4fdfa7dabe2c946fd7491f9556fd"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2ad5ac1576277fc54d768933c36efd1f9ff01acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Coverage class')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "9f34c4263989a3d95af1e5922c1b7d2126655610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Depth distribution')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the depth distributions¶\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "51981795f0dd6b8ca7abe4db367f48313b63811e"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7fb577cdf27f365d4a912728c2a7654d0e60fac8"
   },
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "02967d71ee7f936254ab54acf2aa7c2e038a2b21"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\",dilation_rate = 2)(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\",dilation_rate = 2)(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\",dilation_rate = 4)(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\",dilation_rate= 4)(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\",dilation_rate= 2)(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\",dilation_rate = 2)(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2bd5e479d3aa211bcb5fe32ce9c4d71cd012eefa"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(1)\n",
    "#             continue\n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e25caa2102813289cbd74796b612fbbfaaff8154"
   },
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "072ab621d38cc93d26998f391357cb6efc791600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101, 1)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "30622932f68888e895a9b8cac91810a1bb3c5e75",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 101, 101, 16) 160         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 101, 101, 16) 64          conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 101, 101, 16) 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 101, 101, 16) 2320        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 101, 101, 16) 64          conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 101, 101, 16) 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 101, 101, 16) 2320        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 101, 101, 16) 0           conv2d_141[0][0]                 \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 101, 101, 16) 64          add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 101, 101, 16) 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 101, 101, 16) 2320        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 101, 101, 16) 64          conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 101, 101, 16) 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 101, 101, 16) 2320        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 101, 101, 16) 0           conv2d_143[0][0]                 \n",
      "                                                                 add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 101, 101, 16) 64          add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 101, 101, 16) 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 50, 50, 16)   0           activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 50, 16)   0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 50, 50, 32)   4640        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 50, 50, 32)   128         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 50, 50, 32)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 50, 50, 32)   9248        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 50, 50, 32)   128         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 50, 50, 32)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 50, 50, 32)   9248        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 50, 50, 32)   0           conv2d_146[0][0]                 \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 50, 50, 32)   128         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 50, 50, 32)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 50, 50, 32)   9248        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 50, 50, 32)   128         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 50, 50, 32)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 50, 50, 32)   9248        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 50, 50, 32)   0           conv2d_148[0][0]                 \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 50, 50, 32)   128         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 50, 50, 32)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 25, 25, 32)   0           activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 25, 25, 32)   0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 25, 25, 64)   18496       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 25, 25, 64)   256         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 25, 25, 64)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 25, 25, 64)   36928       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 25, 25, 64)   256         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 25, 25, 64)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 25, 25, 64)   36928       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 25, 25, 64)   0           conv2d_151[0][0]                 \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 25, 25, 64)   256         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 25, 25, 64)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 25, 25, 64)   36928       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 25, 25, 64)   256         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 25, 25, 64)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 25, 25, 64)   36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 25, 25, 64)   0           conv2d_153[0][0]                 \n",
      "                                                                 add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 25, 25, 64)   256         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 25, 25, 64)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 12, 12, 64)   0           activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 12, 12, 64)   0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 128)  73856       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 128)  512         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 128)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 128)  147584      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 128)  512         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 128)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 128)  147584      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 12, 12, 128)  0           conv2d_156[0][0]                 \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 128)  512         add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 12, 12, 128)  147584      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 128)  512         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 128)  147584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 12, 12, 128)  0           conv2d_158[0][0]                 \n",
      "                                                                 add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 128)  512         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 128)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 6, 6, 128)    0           activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 6, 6, 128)    0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 6, 6, 256)    295168      dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 6, 6, 256)    1024        conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 6, 6, 256)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 6, 6, 256)    590080      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 6, 6, 256)    1024        conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 6, 6, 256)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 6, 6, 256)    590080      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 6, 6, 256)    0           conv2d_161[0][0]                 \n",
      "                                                                 conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 6, 6, 256)    1024        add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 6, 6, 256)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 6, 6, 256)    590080      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 6, 6, 256)    1024        conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 6, 6, 256)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 6, 6, 256)    590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 6, 6, 256)    0           conv2d_163[0][0]                 \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 6, 6, 256)    1024        add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 6, 6, 256)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 12, 12, 128)  295040      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 12, 12, 256)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 12, 12, 256)  0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 128)  295040      dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 128)  512         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 128)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 12, 12, 128)  147584      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 12, 128)  512         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 12, 12, 128)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 128)  147584      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 12, 12, 128)  0           conv2d_166[0][0]                 \n",
      "                                                                 conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 12, 12, 128)  512         add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 128)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 128)  147584      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 12, 12, 128)  512         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 12, 12, 128)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 12, 12, 128)  147584      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 12, 12, 128)  0           conv2d_168[0][0]                 \n",
      "                                                                 add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 12, 12, 128)  512         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 12, 12, 128)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 25, 25, 64)   73792       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 25, 25, 128)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 25, 25, 128)  0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 25, 25, 64)   73792       dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 25, 25, 64)   256         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 25, 25, 64)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 25, 25, 64)   36928       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 25, 25, 64)   256         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 25, 25, 64)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 25, 25, 64)   36928       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 25, 25, 64)   0           conv2d_171[0][0]                 \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 25, 25, 64)   256         add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 25, 25, 64)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 25, 25, 64)   36928       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 25, 25, 64)   256         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 25, 25, 64)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 25, 25, 64)   36928       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 25, 25, 64)   0           conv2d_173[0][0]                 \n",
      "                                                                 add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 25, 25, 64)   256         add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 25, 25, 64)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 50, 50, 32)   18464       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 50, 50, 64)   0           conv2d_transpose_15[0][0]        \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 50, 50, 64)   0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 50, 50, 32)   18464       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 50, 50, 32)   128         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 50, 50, 32)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 50, 50, 32)   9248        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 50, 50, 32)   128         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 50, 50, 32)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 50, 50, 32)   9248        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 50, 50, 32)   0           conv2d_176[0][0]                 \n",
      "                                                                 conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 50, 50, 32)   128         add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 50, 50, 32)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 50, 50, 32)   9248        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 50, 50, 32)   128         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 50, 50, 32)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 50, 50, 32)   9248        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 50, 50, 32)   0           conv2d_178[0][0]                 \n",
      "                                                                 add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 50, 50, 32)   128         add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 50, 50, 32)   0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 101, 101, 16) 4624        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 101, 101, 32) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 101, 101, 32) 0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 101, 101, 16) 4624        dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 101, 101, 16) 64          conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 101, 101, 16) 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 101, 101, 16) 2320        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 101, 101, 16) 64          conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 101, 101, 16) 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 101, 101, 16) 2320        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 101, 101, 16) 0           conv2d_181[0][0]                 \n",
      "                                                                 conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 101, 101, 16) 64          add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 101, 101, 16) 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 101, 101, 16) 2320        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 101, 101, 16) 64          conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 101, 101, 16) 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 101, 101, 16) 2320        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 101, 101, 16) 0           conv2d_183[0][0]                 \n",
      "                                                                 add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 101, 101, 16) 64          add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 101, 101, 16) 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 101, 101, 1)  17          activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 101, 101, 1)  0           conv2d_184[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,119,857\n",
      "Trainable params: 5,112,497\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "41699081be465c14e193ffad4fd00bd56840f156",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/150\n",
      " - 87s - loss: 0.3977 - my_iou_metric: 0.4221 - val_loss: 1.2384 - val_my_iou_metric: 0.3900\n",
      "\n",
      "Epoch 00001: my_iou_metric improved from -inf to 0.42214, saving model to dilated_conv.model\n",
      "Epoch 2/150\n",
      " - 72s - loss: 0.3078 - my_iou_metric: 0.5480 - val_loss: 0.7637 - val_my_iou_metric: 0.3139\n",
      "\n",
      "Epoch 00002: my_iou_metric improved from 0.42214 to 0.54797, saving model to dilated_conv.model\n",
      "Epoch 3/150\n",
      " - 72s - loss: 0.2762 - my_iou_metric: 0.5551 - val_loss: 0.3656 - val_my_iou_metric: 0.4690\n",
      "\n",
      "Epoch 00003: my_iou_metric improved from 0.54797 to 0.55508, saving model to dilated_conv.model\n",
      "Epoch 4/150\n",
      " - 71s - loss: 0.2487 - my_iou_metric: 0.5712 - val_loss: 0.3093 - val_my_iou_metric: 0.4843\n",
      "\n",
      "Epoch 00004: my_iou_metric improved from 0.55508 to 0.57117, saving model to dilated_conv.model\n",
      "Epoch 5/150\n",
      " - 72s - loss: 0.2366 - my_iou_metric: 0.5787 - val_loss: 0.3975 - val_my_iou_metric: 0.5192\n",
      "\n",
      "Epoch 00005: my_iou_metric improved from 0.57117 to 0.57873, saving model to dilated_conv.model\n",
      "Epoch 6/150\n",
      " - 72s - loss: 0.2240 - my_iou_metric: 0.5880 - val_loss: 0.9746 - val_my_iou_metric: 0.3935\n",
      "\n",
      "Epoch 00006: my_iou_metric improved from 0.57873 to 0.58803, saving model to dilated_conv.model\n",
      "Epoch 7/150\n",
      " - 72s - loss: 0.2198 - my_iou_metric: 0.6000 - val_loss: 0.2353 - val_my_iou_metric: 0.5001\n",
      "\n",
      "Epoch 00007: my_iou_metric improved from 0.58803 to 0.60003, saving model to dilated_conv.model\n",
      "Epoch 8/150\n",
      " - 72s - loss: 0.2077 - my_iou_metric: 0.6201 - val_loss: 0.2795 - val_my_iou_metric: 0.5958\n",
      "\n",
      "Epoch 00008: my_iou_metric improved from 0.60003 to 0.62008, saving model to dilated_conv.model\n",
      "Epoch 9/150\n",
      " - 72s - loss: 0.1936 - my_iou_metric: 0.6335 - val_loss: 0.2684 - val_my_iou_metric: 0.4979\n",
      "\n",
      "Epoch 00009: my_iou_metric improved from 0.62008 to 0.63352, saving model to dilated_conv.model\n",
      "Epoch 10/150\n",
      " - 72s - loss: 0.1893 - my_iou_metric: 0.6484 - val_loss: 0.2196 - val_my_iou_metric: 0.6375\n",
      "\n",
      "Epoch 00010: my_iou_metric improved from 0.63352 to 0.64841, saving model to dilated_conv.model\n",
      "Epoch 11/150\n",
      " - 72s - loss: 0.1910 - my_iou_metric: 0.6417 - val_loss: 0.3738 - val_my_iou_metric: 0.4489\n",
      "\n",
      "Epoch 00011: my_iou_metric did not improve from 0.64841\n",
      "Epoch 12/150\n",
      " - 72s - loss: 0.1870 - my_iou_metric: 0.6495 - val_loss: 0.4182 - val_my_iou_metric: 0.5681\n",
      "\n",
      "Epoch 00012: my_iou_metric improved from 0.64841 to 0.64945, saving model to dilated_conv.model\n",
      "Epoch 13/150\n",
      " - 72s - loss: 0.1725 - my_iou_metric: 0.6720 - val_loss: 0.1847 - val_my_iou_metric: 0.6621\n",
      "\n",
      "Epoch 00013: my_iou_metric improved from 0.64945 to 0.67200, saving model to dilated_conv.model\n",
      "Epoch 14/150\n",
      " - 72s - loss: 0.1701 - my_iou_metric: 0.6754 - val_loss: 0.2976 - val_my_iou_metric: 0.5520\n",
      "\n",
      "Epoch 00014: my_iou_metric improved from 0.67200 to 0.67536, saving model to dilated_conv.model\n",
      "Epoch 15/150\n",
      " - 72s - loss: 0.1716 - my_iou_metric: 0.6711 - val_loss: 0.3507 - val_my_iou_metric: 0.5049\n",
      "\n",
      "Epoch 00015: my_iou_metric did not improve from 0.67536\n",
      "Epoch 16/150\n",
      " - 72s - loss: 0.1656 - my_iou_metric: 0.6796 - val_loss: 0.1883 - val_my_iou_metric: 0.6899\n",
      "\n",
      "Epoch 00016: my_iou_metric improved from 0.67536 to 0.67961, saving model to dilated_conv.model\n",
      "Epoch 17/150\n",
      " - 72s - loss: 0.1631 - my_iou_metric: 0.6813 - val_loss: 0.1667 - val_my_iou_metric: 0.7041\n",
      "\n",
      "Epoch 00017: my_iou_metric improved from 0.67961 to 0.68125, saving model to dilated_conv.model\n",
      "Epoch 18/150\n",
      " - 72s - loss: 0.1545 - my_iou_metric: 0.6952 - val_loss: 0.1667 - val_my_iou_metric: 0.6550\n",
      "\n",
      "Epoch 00018: my_iou_metric improved from 0.68125 to 0.69516, saving model to dilated_conv.model\n",
      "Epoch 19/150\n",
      " - 72s - loss: 0.1524 - my_iou_metric: 0.6938 - val_loss: 0.2283 - val_my_iou_metric: 0.6395\n",
      "\n",
      "Epoch 00019: my_iou_metric did not improve from 0.69516\n",
      "Epoch 20/150\n",
      " - 72s - loss: 0.1521 - my_iou_metric: 0.6947 - val_loss: 0.2119 - val_my_iou_metric: 0.6529\n",
      "\n",
      "Epoch 00020: my_iou_metric did not improve from 0.69516\n",
      "Epoch 21/150\n",
      " - 72s - loss: 0.1529 - my_iou_metric: 0.7037 - val_loss: 0.1722 - val_my_iou_metric: 0.6488\n",
      "\n",
      "Epoch 00021: my_iou_metric improved from 0.69516 to 0.70369, saving model to dilated_conv.model\n",
      "Epoch 22/150\n",
      " - 72s - loss: 0.1455 - my_iou_metric: 0.7086 - val_loss: 0.2031 - val_my_iou_metric: 0.6791\n",
      "\n",
      "Epoch 00022: my_iou_metric improved from 0.70369 to 0.70861, saving model to dilated_conv.model\n",
      "Epoch 23/150\n",
      " - 72s - loss: 0.1439 - my_iou_metric: 0.7039 - val_loss: 0.3056 - val_my_iou_metric: 0.5903\n",
      "\n",
      "Epoch 00023: my_iou_metric did not improve from 0.70861\n",
      "Epoch 24/150\n",
      " - 72s - loss: 0.1435 - my_iou_metric: 0.7086 - val_loss: 0.1770 - val_my_iou_metric: 0.7135\n",
      "\n",
      "Epoch 00024: my_iou_metric improved from 0.70861 to 0.70862, saving model to dilated_conv.model\n",
      "Epoch 25/150\n",
      " - 72s - loss: 0.1426 - my_iou_metric: 0.7182 - val_loss: 0.1511 - val_my_iou_metric: 0.7264\n",
      "\n",
      "Epoch 00025: my_iou_metric improved from 0.70862 to 0.71822, saving model to dilated_conv.model\n",
      "Epoch 26/150\n",
      " - 72s - loss: 0.1419 - my_iou_metric: 0.7198 - val_loss: 0.1670 - val_my_iou_metric: 0.7085\n",
      "\n",
      "Epoch 00026: my_iou_metric improved from 0.71822 to 0.71980, saving model to dilated_conv.model\n",
      "Epoch 27/150\n",
      " - 72s - loss: 0.1299 - my_iou_metric: 0.7267 - val_loss: 0.1561 - val_my_iou_metric: 0.7422\n",
      "\n",
      "Epoch 00027: my_iou_metric improved from 0.71980 to 0.72672, saving model to dilated_conv.model\n",
      "Epoch 28/150\n",
      " - 72s - loss: 0.1295 - my_iou_metric: 0.7257 - val_loss: 0.3470 - val_my_iou_metric: 0.5799\n",
      "\n",
      "Epoch 00028: my_iou_metric did not improve from 0.72672\n",
      "Epoch 29/150\n",
      " - 72s - loss: 0.1403 - my_iou_metric: 0.7222 - val_loss: 0.2809 - val_my_iou_metric: 0.6424\n",
      "\n",
      "Epoch 00029: my_iou_metric did not improve from 0.72672\n",
      "Epoch 30/150\n",
      " - 72s - loss: 0.1309 - my_iou_metric: 0.7320 - val_loss: 0.1460 - val_my_iou_metric: 0.7342\n",
      "\n",
      "Epoch 00030: my_iou_metric improved from 0.72672 to 0.73200, saving model to dilated_conv.model\n",
      "Epoch 31/150\n",
      " - 72s - loss: 0.1306 - my_iou_metric: 0.7302 - val_loss: 0.1419 - val_my_iou_metric: 0.7425\n",
      "\n",
      "Epoch 00031: my_iou_metric did not improve from 0.73200\n",
      "Epoch 32/150\n",
      " - 72s - loss: 0.1254 - my_iou_metric: 0.7422 - val_loss: 0.1520 - val_my_iou_metric: 0.7391\n",
      "\n",
      "Epoch 00032: my_iou_metric improved from 0.73200 to 0.74216, saving model to dilated_conv.model\n",
      "Epoch 33/150\n",
      " - 72s - loss: 0.1271 - my_iou_metric: 0.7355 - val_loss: 0.1737 - val_my_iou_metric: 0.7129\n",
      "\n",
      "Epoch 00033: my_iou_metric did not improve from 0.74216\n",
      "Epoch 34/150\n",
      " - 72s - loss: 0.1230 - my_iou_metric: 0.7353 - val_loss: 0.1440 - val_my_iou_metric: 0.7165\n",
      "\n",
      "Epoch 00034: my_iou_metric did not improve from 0.74216\n",
      "Epoch 35/150\n",
      " - 72s - loss: 0.1173 - my_iou_metric: 0.7475 - val_loss: 0.1732 - val_my_iou_metric: 0.6806\n",
      "\n",
      "Epoch 00035: my_iou_metric improved from 0.74216 to 0.74745, saving model to dilated_conv.model\n",
      "Epoch 36/150\n",
      " - 72s - loss: 0.1189 - my_iou_metric: 0.7403 - val_loss: 0.1385 - val_my_iou_metric: 0.7145\n",
      "\n",
      "Epoch 00036: my_iou_metric did not improve from 0.74745\n",
      "Epoch 37/150\n",
      " - 72s - loss: 0.1194 - my_iou_metric: 0.7464 - val_loss: 0.1314 - val_my_iou_metric: 0.7591\n",
      "\n",
      "Epoch 00037: my_iou_metric did not improve from 0.74745\n",
      "Epoch 38/150\n",
      " - 72s - loss: 0.1208 - my_iou_metric: 0.7413 - val_loss: 0.1419 - val_my_iou_metric: 0.7540\n",
      "\n",
      "Epoch 00038: my_iou_metric did not improve from 0.74745\n",
      "Epoch 39/150\n",
      " - 72s - loss: 0.1142 - my_iou_metric: 0.7483 - val_loss: 0.1623 - val_my_iou_metric: 0.7055\n",
      "\n",
      "Epoch 00039: my_iou_metric improved from 0.74745 to 0.74825, saving model to dilated_conv.model\n",
      "Epoch 40/150\n",
      " - 72s - loss: 0.1148 - my_iou_metric: 0.7483 - val_loss: 0.1729 - val_my_iou_metric: 0.7370\n",
      "\n",
      "Epoch 00040: my_iou_metric improved from 0.74825 to 0.74828, saving model to dilated_conv.model\n",
      "Epoch 41/150\n",
      " - 72s - loss: 0.1102 - my_iou_metric: 0.7582 - val_loss: 0.1703 - val_my_iou_metric: 0.7179\n",
      "\n",
      "Epoch 00041: my_iou_metric improved from 0.74828 to 0.75825, saving model to dilated_conv.model\n",
      "Epoch 42/150\n",
      " - 72s - loss: 0.1069 - my_iou_metric: 0.7546 - val_loss: 0.2291 - val_my_iou_metric: 0.7155\n",
      "\n",
      "Epoch 00042: my_iou_metric did not improve from 0.75825\n",
      "Epoch 43/150\n",
      " - 72s - loss: 0.1115 - my_iou_metric: 0.7509 - val_loss: 1.1892 - val_my_iou_metric: 0.4184\n",
      "\n",
      "Epoch 00043: my_iou_metric did not improve from 0.75825\n",
      "Epoch 44/150\n",
      " - 73s - loss: 0.1150 - my_iou_metric: 0.7471 - val_loss: 0.1462 - val_my_iou_metric: 0.7293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: my_iou_metric did not improve from 0.75825\n",
      "Epoch 45/150\n",
      " - 72s - loss: 0.1075 - my_iou_metric: 0.7530 - val_loss: 0.1312 - val_my_iou_metric: 0.7322\n",
      "\n",
      "Epoch 00045: my_iou_metric did not improve from 0.75825\n",
      "Epoch 46/150\n",
      " - 72s - loss: 0.1091 - my_iou_metric: 0.7513 - val_loss: 0.1575 - val_my_iou_metric: 0.7509\n",
      "\n",
      "Epoch 00046: my_iou_metric did not improve from 0.75825\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 47/150\n",
      " - 72s - loss: 0.0922 - my_iou_metric: 0.7763 - val_loss: 0.1384 - val_my_iou_metric: 0.7705\n",
      "\n",
      "Epoch 00047: my_iou_metric improved from 0.75825 to 0.77633, saving model to dilated_conv.model\n",
      "Epoch 48/150\n",
      " - 72s - loss: 0.0860 - my_iou_metric: 0.7766 - val_loss: 0.1723 - val_my_iou_metric: 0.7285\n",
      "\n",
      "Epoch 00048: my_iou_metric improved from 0.77633 to 0.77661, saving model to dilated_conv.model\n",
      "Epoch 49/150\n",
      " - 72s - loss: 0.0854 - my_iou_metric: 0.7876 - val_loss: 0.1605 - val_my_iou_metric: 0.7506\n",
      "\n",
      "Epoch 00049: my_iou_metric improved from 0.77661 to 0.78758, saving model to dilated_conv.model\n",
      "Epoch 50/150\n",
      " - 72s - loss: 0.0857 - my_iou_metric: 0.7785 - val_loss: 0.1466 - val_my_iou_metric: 0.7730\n",
      "\n",
      "Epoch 00050: my_iou_metric did not improve from 0.78758\n",
      "Epoch 51/150\n",
      " - 72s - loss: 0.0849 - my_iou_metric: 0.7827 - val_loss: 0.1911 - val_my_iou_metric: 0.7436\n",
      "\n",
      "Epoch 00051: my_iou_metric did not improve from 0.78758\n",
      "Epoch 52/150\n",
      " - 72s - loss: 0.0832 - my_iou_metric: 0.7817 - val_loss: 0.1607 - val_my_iou_metric: 0.7551\n",
      "\n",
      "Epoch 00052: my_iou_metric did not improve from 0.78758\n",
      "Epoch 53/150\n",
      " - 72s - loss: 0.0853 - my_iou_metric: 0.7800 - val_loss: 0.2294 - val_my_iou_metric: 0.6925\n",
      "\n",
      "Epoch 00053: my_iou_metric did not improve from 0.78758\n",
      "Epoch 54/150\n",
      " - 72s - loss: 0.0838 - my_iou_metric: 0.7787 - val_loss: 0.1354 - val_my_iou_metric: 0.7634\n",
      "\n",
      "Epoch 00054: my_iou_metric did not improve from 0.78758\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 55/150\n",
      " - 72s - loss: 0.0722 - my_iou_metric: 0.7954 - val_loss: 0.1501 - val_my_iou_metric: 0.7620\n",
      "\n",
      "Epoch 00055: my_iou_metric improved from 0.78758 to 0.79536, saving model to dilated_conv.model\n",
      "Epoch 56/150\n",
      " - 72s - loss: 0.0727 - my_iou_metric: 0.7942 - val_loss: 0.1713 - val_my_iou_metric: 0.7607\n",
      "\n",
      "Epoch 00056: my_iou_metric did not improve from 0.79536\n",
      "Epoch 57/150\n",
      " - 72s - loss: 0.0718 - my_iou_metric: 0.7989 - val_loss: 0.1602 - val_my_iou_metric: 0.7723\n",
      "\n",
      "Epoch 00057: my_iou_metric improved from 0.79536 to 0.79891, saving model to dilated_conv.model\n",
      "Epoch 58/150\n",
      " - 72s - loss: 0.0716 - my_iou_metric: 0.7982 - val_loss: 0.1576 - val_my_iou_metric: 0.7740\n",
      "\n",
      "Epoch 00058: my_iou_metric did not improve from 0.79891\n",
      "Epoch 59/150\n",
      " - 72s - loss: 0.0687 - my_iou_metric: 0.7969 - val_loss: 0.1793 - val_my_iou_metric: 0.7555\n",
      "\n",
      "Epoch 00059: my_iou_metric did not improve from 0.79891\n",
      "Epoch 60/150\n",
      " - 72s - loss: 0.0684 - my_iou_metric: 0.8010 - val_loss: 0.1850 - val_my_iou_metric: 0.7396\n",
      "\n",
      "Epoch 00060: my_iou_metric improved from 0.79891 to 0.80100, saving model to dilated_conv.model\n",
      "Epoch 61/150\n",
      " - 72s - loss: 0.0688 - my_iou_metric: 0.8010 - val_loss: 0.1561 - val_my_iou_metric: 0.7694\n",
      "\n",
      "Epoch 00061: my_iou_metric improved from 0.80100 to 0.80100, saving model to dilated_conv.model\n",
      "Epoch 62/150\n",
      " - 72s - loss: 0.0682 - my_iou_metric: 0.7995 - val_loss: 0.1586 - val_my_iou_metric: 0.7596\n",
      "\n",
      "Epoch 00062: my_iou_metric did not improve from 0.80100\n",
      "Epoch 63/150\n",
      " - 72s - loss: 0.0670 - my_iou_metric: 0.8008 - val_loss: 0.1755 - val_my_iou_metric: 0.7635\n",
      "\n",
      "Epoch 00063: my_iou_metric did not improve from 0.80100\n",
      "Epoch 64/150\n",
      " - 72s - loss: 0.0680 - my_iou_metric: 0.7967 - val_loss: 0.1645 - val_my_iou_metric: 0.7726\n",
      "\n",
      "Epoch 00064: my_iou_metric did not improve from 0.80100\n",
      "Epoch 65/150\n",
      " - 72s - loss: 0.0655 - my_iou_metric: 0.8025 - val_loss: 0.1778 - val_my_iou_metric: 0.7756\n",
      "\n",
      "Epoch 00065: my_iou_metric improved from 0.80100 to 0.80255, saving model to dilated_conv.model\n",
      "Epoch 66/150\n",
      " - 72s - loss: 0.0691 - my_iou_metric: 0.7945 - val_loss: 0.1586 - val_my_iou_metric: 0.7562\n",
      "\n",
      "Epoch 00066: my_iou_metric did not improve from 0.80255\n",
      "Epoch 67/150\n",
      " - 72s - loss: 0.0674 - my_iou_metric: 0.7992 - val_loss: 0.1597 - val_my_iou_metric: 0.7753\n",
      "\n",
      "Epoch 00067: my_iou_metric did not improve from 0.80255\n",
      "Epoch 68/150\n",
      " - 72s - loss: 0.0632 - my_iou_metric: 0.8026 - val_loss: 0.2240 - val_my_iou_metric: 0.7559\n",
      "\n",
      "Epoch 00068: my_iou_metric improved from 0.80255 to 0.80264, saving model to dilated_conv.model\n",
      "Epoch 69/150\n",
      " - 72s - loss: 0.0659 - my_iou_metric: 0.8038 - val_loss: 0.1651 - val_my_iou_metric: 0.7749\n",
      "\n",
      "Epoch 00069: my_iou_metric improved from 0.80264 to 0.80377, saving model to dilated_conv.model\n",
      "Epoch 70/150\n",
      " - 72s - loss: 0.0645 - my_iou_metric: 0.8076 - val_loss: 0.1583 - val_my_iou_metric: 0.7560\n",
      "\n",
      "Epoch 00070: my_iou_metric improved from 0.80377 to 0.80756, saving model to dilated_conv.model\n",
      "Epoch 71/150\n",
      " - 72s - loss: 0.0663 - my_iou_metric: 0.8007 - val_loss: 0.1552 - val_my_iou_metric: 0.7659\n",
      "\n",
      "Epoch 00071: my_iou_metric did not improve from 0.80756\n",
      "Epoch 72/150\n",
      " - 72s - loss: 0.0651 - my_iou_metric: 0.8016 - val_loss: 0.2419 - val_my_iou_metric: 0.7364\n",
      "\n",
      "Epoch 00072: my_iou_metric did not improve from 0.80756\n",
      "Epoch 73/150\n",
      " - 72s - loss: 0.0635 - my_iou_metric: 0.8002 - val_loss: 0.1542 - val_my_iou_metric: 0.7743\n",
      "\n",
      "Epoch 00073: my_iou_metric did not improve from 0.80756\n",
      "Epoch 74/150\n",
      " - 72s - loss: 0.0648 - my_iou_metric: 0.8023 - val_loss: 0.1569 - val_my_iou_metric: 0.7726\n",
      "\n",
      "Epoch 00074: my_iou_metric did not improve from 0.80756\n",
      "Epoch 75/150\n",
      " - 72s - loss: 0.0635 - my_iou_metric: 0.8055 - val_loss: 0.1547 - val_my_iou_metric: 0.7705\n",
      "\n",
      "Epoch 00075: my_iou_metric did not improve from 0.80756\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 76/150\n",
      " - 72s - loss: 0.0588 - my_iou_metric: 0.8103 - val_loss: 0.1641 - val_my_iou_metric: 0.7810\n",
      "\n",
      "Epoch 00076: my_iou_metric improved from 0.80756 to 0.81025, saving model to dilated_conv.model\n",
      "Epoch 77/150\n",
      " - 72s - loss: 0.0601 - my_iou_metric: 0.8118 - val_loss: 0.1572 - val_my_iou_metric: 0.7701\n",
      "\n",
      "Epoch 00077: my_iou_metric improved from 0.81025 to 0.81177, saving model to dilated_conv.model\n",
      "Epoch 78/150\n",
      " - 72s - loss: 0.0578 - my_iou_metric: 0.8103 - val_loss: 0.1591 - val_my_iou_metric: 0.7743\n",
      "\n",
      "Epoch 00078: my_iou_metric did not improve from 0.81177\n",
      "Epoch 79/150\n",
      " - 72s - loss: 0.0586 - my_iou_metric: 0.8119 - val_loss: 0.1617 - val_my_iou_metric: 0.7636\n",
      "\n",
      "Epoch 00079: my_iou_metric improved from 0.81177 to 0.81186, saving model to dilated_conv.model\n",
      "Epoch 80/150\n",
      " - 72s - loss: 0.0575 - my_iou_metric: 0.8109 - val_loss: 0.1689 - val_my_iou_metric: 0.7725\n",
      "\n",
      "Epoch 00080: my_iou_metric did not improve from 0.81186\n",
      "Epoch 81/150\n",
      " - 72s - loss: 0.0563 - my_iou_metric: 0.8129 - val_loss: 0.2070 - val_my_iou_metric: 0.7505\n",
      "\n",
      "Epoch 00081: my_iou_metric improved from 0.81186 to 0.81292, saving model to dilated_conv.model\n",
      "Epoch 82/150\n",
      " - 72s - loss: 0.0542 - my_iou_metric: 0.8154 - val_loss: 0.1823 - val_my_iou_metric: 0.7686\n",
      "\n",
      "Epoch 00082: my_iou_metric improved from 0.81292 to 0.81541, saving model to dilated_conv.model\n",
      "Epoch 83/150\n",
      " - 72s - loss: 0.0560 - my_iou_metric: 0.8151 - val_loss: 0.1610 - val_my_iou_metric: 0.7757\n",
      "\n",
      "Epoch 00083: my_iou_metric did not improve from 0.81541\n",
      "Epoch 84/150\n",
      " - 72s - loss: 0.0545 - my_iou_metric: 0.8138 - val_loss: 0.1777 - val_my_iou_metric: 0.7776\n",
      "\n",
      "Epoch 00084: my_iou_metric did not improve from 0.81541\n",
      "Epoch 85/150\n",
      " - 72s - loss: 0.0553 - my_iou_metric: 0.8135 - val_loss: 0.1953 - val_my_iou_metric: 0.7594\n",
      "\n",
      "Epoch 00085: my_iou_metric did not improve from 0.81541\n",
      "Epoch 86/150\n",
      " - 72s - loss: 0.0540 - my_iou_metric: 0.8148 - val_loss: 0.1835 - val_my_iou_metric: 0.7665\n",
      "\n",
      "Epoch 00086: my_iou_metric did not improve from 0.81541\n",
      "Epoch 87/150\n",
      " - 72s - loss: 0.0553 - my_iou_metric: 0.8099 - val_loss: 0.1926 - val_my_iou_metric: 0.7525\n",
      "\n",
      "Epoch 00087: my_iou_metric did not improve from 0.81541\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 88/150\n",
      " - 72s - loss: 0.0548 - my_iou_metric: 0.8129 - val_loss: 0.1825 - val_my_iou_metric: 0.7621\n",
      "\n",
      "Epoch 00088: my_iou_metric did not improve from 0.81541\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 72s - loss: 0.0546 - my_iou_metric: 0.8163 - val_loss: 0.1727 - val_my_iou_metric: 0.7672\n",
      "\n",
      "Epoch 00089: my_iou_metric improved from 0.81541 to 0.81633, saving model to dilated_conv.model\n",
      "Epoch 90/150\n",
      " - 72s - loss: 0.0541 - my_iou_metric: 0.8181 - val_loss: 0.1727 - val_my_iou_metric: 0.7703\n",
      "\n",
      "Epoch 00090: my_iou_metric improved from 0.81633 to 0.81809, saving model to dilated_conv.model\n",
      "Epoch 91/150\n",
      " - 72s - loss: 0.0543 - my_iou_metric: 0.8127 - val_loss: 0.1792 - val_my_iou_metric: 0.7782\n",
      "\n",
      "Epoch 00091: my_iou_metric did not improve from 0.81809\n",
      "Epoch 92/150\n",
      " - 72s - loss: 0.0525 - my_iou_metric: 0.8183 - val_loss: 0.1861 - val_my_iou_metric: 0.7631\n",
      "\n",
      "Epoch 00092: my_iou_metric improved from 0.81809 to 0.81830, saving model to dilated_conv.model\n",
      "Epoch 93/150\n",
      " - 72s - loss: 0.0542 - my_iou_metric: 0.8150 - val_loss: 0.1697 - val_my_iou_metric: 0.7702\n",
      "\n",
      "Epoch 00093: my_iou_metric did not improve from 0.81830\n",
      "Epoch 94/150\n",
      " - 72s - loss: 0.0534 - my_iou_metric: 0.8150 - val_loss: 0.1804 - val_my_iou_metric: 0.7614\n",
      "\n",
      "Epoch 00094: my_iou_metric did not improve from 0.81830\n",
      "Epoch 95/150\n",
      " - 72s - loss: 0.0516 - my_iou_metric: 0.8191 - val_loss: 0.1846 - val_my_iou_metric: 0.7692\n",
      "\n",
      "Epoch 00095: my_iou_metric improved from 0.81830 to 0.81906, saving model to dilated_conv.model\n",
      "Epoch 96/150\n",
      " - 72s - loss: 0.0536 - my_iou_metric: 0.8155 - val_loss: 0.1676 - val_my_iou_metric: 0.7705\n",
      "\n",
      "Epoch 00096: my_iou_metric did not improve from 0.81906\n",
      "Epoch 97/150\n",
      " - 72s - loss: 0.0532 - my_iou_metric: 0.8155 - val_loss: 0.1808 - val_my_iou_metric: 0.7629\n",
      "\n",
      "Epoch 00097: my_iou_metric did not improve from 0.81906\n",
      "Epoch 98/150\n",
      " - 72s - loss: 0.0542 - my_iou_metric: 0.8104 - val_loss: 0.1794 - val_my_iou_metric: 0.7584\n",
      "\n",
      "Epoch 00098: my_iou_metric did not improve from 0.81906\n",
      "Epoch 99/150\n",
      " - 72s - loss: 0.0520 - my_iou_metric: 0.8187 - val_loss: 0.1845 - val_my_iou_metric: 0.7614\n",
      "\n",
      "Epoch 00099: my_iou_metric did not improve from 0.81906\n",
      "Epoch 100/150\n",
      " - 72s - loss: 0.0516 - my_iou_metric: 0.8179 - val_loss: 0.1877 - val_my_iou_metric: 0.7632\n",
      "\n",
      "Epoch 00100: my_iou_metric did not improve from 0.81906\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 101/150\n",
      " - 72s - loss: 0.0515 - my_iou_metric: 0.8158 - val_loss: 0.1878 - val_my_iou_metric: 0.7665\n",
      "\n",
      "Epoch 00101: my_iou_metric did not improve from 0.81906\n",
      "Epoch 102/150\n",
      " - 72s - loss: 0.0516 - my_iou_metric: 0.8161 - val_loss: 0.1948 - val_my_iou_metric: 0.7639\n",
      "\n",
      "Epoch 00102: my_iou_metric did not improve from 0.81906\n",
      "Epoch 103/150\n",
      " - 72s - loss: 0.0512 - my_iou_metric: 0.8198 - val_loss: 0.1888 - val_my_iou_metric: 0.7669\n",
      "\n",
      "Epoch 00103: my_iou_metric improved from 0.81906 to 0.81977, saving model to dilated_conv.model\n",
      "Epoch 104/150\n",
      " - 72s - loss: 0.0499 - my_iou_metric: 0.8199 - val_loss: 0.1806 - val_my_iou_metric: 0.7685\n",
      "\n",
      "Epoch 00104: my_iou_metric improved from 0.81977 to 0.81992, saving model to dilated_conv.model\n",
      "Epoch 105/150\n",
      " - 72s - loss: 0.0513 - my_iou_metric: 0.8185 - val_loss: 0.1841 - val_my_iou_metric: 0.7716\n",
      "\n",
      "Epoch 00105: my_iou_metric did not improve from 0.81992\n",
      "Epoch 106/150\n",
      " - 72s - loss: 0.0510 - my_iou_metric: 0.8214 - val_loss: 0.1822 - val_my_iou_metric: 0.7695\n",
      "\n",
      "Epoch 00106: my_iou_metric improved from 0.81992 to 0.82138, saving model to dilated_conv.model\n",
      "Epoch 107/150\n",
      " - 73s - loss: 0.0513 - my_iou_metric: 0.8188 - val_loss: 0.1904 - val_my_iou_metric: 0.7668\n",
      "\n",
      "Epoch 00107: my_iou_metric did not improve from 0.82138\n",
      "Epoch 108/150\n",
      " - 72s - loss: 0.0503 - my_iou_metric: 0.8176 - val_loss: 0.1845 - val_my_iou_metric: 0.7730\n",
      "\n",
      "Epoch 00108: my_iou_metric did not improve from 0.82138\n",
      "Epoch 109/150\n",
      " - 72s - loss: 0.0507 - my_iou_metric: 0.8202 - val_loss: 0.1883 - val_my_iou_metric: 0.7681\n",
      "\n",
      "Epoch 00109: my_iou_metric did not improve from 0.82138\n",
      "Epoch 110/150\n",
      " - 73s - loss: 0.0505 - my_iou_metric: 0.8205 - val_loss: 0.1928 - val_my_iou_metric: 0.7705\n",
      "\n",
      "Epoch 00110: my_iou_metric did not improve from 0.82138\n",
      "Epoch 111/150\n",
      " - 72s - loss: 0.0491 - my_iou_metric: 0.8220 - val_loss: 0.1843 - val_my_iou_metric: 0.7755\n",
      "\n",
      "Epoch 00111: my_iou_metric improved from 0.82138 to 0.82195, saving model to dilated_conv.model\n",
      "Epoch 112/150\n",
      " - 72s - loss: 0.0524 - my_iou_metric: 0.8171 - val_loss: 0.1881 - val_my_iou_metric: 0.7714\n",
      "\n",
      "Epoch 00112: my_iou_metric did not improve from 0.82195\n",
      "Epoch 113/150\n",
      " - 72s - loss: 0.0506 - my_iou_metric: 0.8213 - val_loss: 0.1925 - val_my_iou_metric: 0.7681\n",
      "\n",
      "Epoch 00113: my_iou_metric did not improve from 0.82195\n",
      "Epoch 114/150\n",
      " - 72s - loss: 0.0503 - my_iou_metric: 0.8227 - val_loss: 0.1872 - val_my_iou_metric: 0.7701\n",
      "\n",
      "Epoch 00114: my_iou_metric improved from 0.82195 to 0.82270, saving model to dilated_conv.model\n",
      "Epoch 115/150\n",
      " - 72s - loss: 0.0497 - my_iou_metric: 0.8205 - val_loss: 0.1956 - val_my_iou_metric: 0.7699\n",
      "\n",
      "Epoch 00115: my_iou_metric did not improve from 0.82270\n",
      "Epoch 116/150\n",
      " - 72s - loss: 0.0495 - my_iou_metric: 0.8217 - val_loss: 0.1985 - val_my_iou_metric: 0.7705\n",
      "\n",
      "Epoch 00116: my_iou_metric did not improve from 0.82270\n",
      "Epoch 117/150\n",
      " - 72s - loss: 0.0498 - my_iou_metric: 0.8236 - val_loss: 0.1989 - val_my_iou_metric: 0.7690\n",
      "\n",
      "Epoch 00117: my_iou_metric improved from 0.82270 to 0.82361, saving model to dilated_conv.model\n",
      "Epoch 118/150\n",
      " - 72s - loss: 0.0490 - my_iou_metric: 0.8218 - val_loss: 0.2011 - val_my_iou_metric: 0.7703\n",
      "\n",
      "Epoch 00118: my_iou_metric did not improve from 0.82361\n",
      "Epoch 119/150\n",
      " - 72s - loss: 0.0501 - my_iou_metric: 0.8221 - val_loss: 0.1966 - val_my_iou_metric: 0.7694\n",
      "\n",
      "Epoch 00119: my_iou_metric did not improve from 0.82361\n",
      "Epoch 120/150\n",
      " - 72s - loss: 0.0508 - my_iou_metric: 0.8185 - val_loss: 0.2049 - val_my_iou_metric: 0.7636\n",
      "\n",
      "Epoch 00120: my_iou_metric did not improve from 0.82361\n",
      "Epoch 121/150\n",
      " - 72s - loss: 0.0506 - my_iou_metric: 0.8212 - val_loss: 0.1964 - val_my_iou_metric: 0.7728\n",
      "\n",
      "Epoch 00121: my_iou_metric did not improve from 0.82361\n",
      "Epoch 122/150\n",
      " - 72s - loss: 0.0499 - my_iou_metric: 0.8203 - val_loss: 0.2027 - val_my_iou_metric: 0.7716\n",
      "\n",
      "Epoch 00122: my_iou_metric did not improve from 0.82361\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 123/150\n",
      " - 72s - loss: 0.0503 - my_iou_metric: 0.8220 - val_loss: 0.1897 - val_my_iou_metric: 0.7771\n",
      "\n",
      "Epoch 00123: my_iou_metric did not improve from 0.82361\n",
      "Epoch 124/150\n",
      " - 72s - loss: 0.0494 - my_iou_metric: 0.8247 - val_loss: 0.1945 - val_my_iou_metric: 0.7708\n",
      "\n",
      "Epoch 00124: my_iou_metric improved from 0.82361 to 0.82469, saving model to dilated_conv.model\n",
      "Epoch 125/150\n",
      " - 72s - loss: 0.0485 - my_iou_metric: 0.8202 - val_loss: 0.2003 - val_my_iou_metric: 0.7673\n",
      "\n",
      "Epoch 00125: my_iou_metric did not improve from 0.82469\n",
      "Epoch 126/150\n",
      " - 72s - loss: 0.0484 - my_iou_metric: 0.8199 - val_loss: 0.1972 - val_my_iou_metric: 0.7706\n",
      "\n",
      "Epoch 00126: my_iou_metric did not improve from 0.82469\n",
      "Epoch 127/150\n",
      " - 72s - loss: 0.0478 - my_iou_metric: 0.8220 - val_loss: 0.1974 - val_my_iou_metric: 0.7741\n",
      "\n",
      "Epoch 00127: my_iou_metric did not improve from 0.82469\n",
      "Epoch 128/150\n",
      " - 72s - loss: 0.0493 - my_iou_metric: 0.8182 - val_loss: 0.1928 - val_my_iou_metric: 0.7702\n",
      "\n",
      "Epoch 00128: my_iou_metric did not improve from 0.82469\n",
      "Epoch 129/150\n",
      " - 72s - loss: 0.0506 - my_iou_metric: 0.8220 - val_loss: 0.1952 - val_my_iou_metric: 0.7736\n",
      "\n",
      "Epoch 00129: my_iou_metric did not improve from 0.82469\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 130/150\n",
      " - 72s - loss: 0.0489 - my_iou_metric: 0.8224 - val_loss: 0.1929 - val_my_iou_metric: 0.7754\n",
      "\n",
      "Epoch 00130: my_iou_metric did not improve from 0.82469\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-65551e0b6342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     verbose=2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "513a3f8490ae5cbc61651458750ba369f99f6f62",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "# model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.nadam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,'lovasz_loss': lovasz_loss})\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bc68a1d9f9ec3837a2988bd7fe05d1fffdbc381d",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-865bb391af2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('ep{epoch:03d}_dilated.h5',monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.3, patience=5, min_lr=0.0001, verbose=1)\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "347c6567c95430f28ec51b94f42603e37a4056db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9224ab8a2d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"my_iou_metric_2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "a081f8f61a713457c8c8f3979a78f75541875456"
   },
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f68651e1ce6ad9a461c8f1a25a1250fd489adfed"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b7a061700364ea17735f953d6bd3c835bc3dc630"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5a9b1a900a8a4d031978c3b5ef2e739b5661de73"
   },
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "91b1be75d7e8ff74db956c8c846c47ed7576ecb2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87848539b18b4532a68f53a31a0806ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.7925    0.7935    0.796375  0.796875  0.797     0.798     0.797375\n",
      "  0.798     0.798875  0.799     0.798375  0.798     0.7985    0.797625\n",
      "  0.797375  0.796375  0.7985    0.798125  0.797375  0.797     0.796\n",
      "  0.796375  0.7955    0.794875  0.79475   0.794     0.793     0.793375\n",
      "  0.792125  0.791     0.789875]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "1beb285910aa6532d7a69a70afa6a9671e6d347d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f145838da58>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "2c4852ecf2c504a4ce30e975f5e36b534c2111e6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "21bb50645b1c67d907e42c262d92f975668fccac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f78f5675984cf9898fd660021cfa02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "ce8185fa64aafbe42ebde98aba984b4f22b0050e"
   },
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "7ccac81a492b9caaff4a25401165e145cf2c6f8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd634afbe6594a7cbffce9f5cbe162a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "770d7d596656f4f1ad17a6063ad662ac80e11b24"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c89c406884ee54bee2c57aff51b116c157553ae9"
   },
   "outputs": [],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3009187c164635fbe163bd8ce406c2e309b1e5f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
